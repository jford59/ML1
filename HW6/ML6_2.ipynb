{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGPQ4X5wgTHfGt3EJbOYTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jford59/ML1/blob/main/HW6/ML6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okFotGL9ztve",
        "outputId": "d513a551-46a5-40d3-cc98-f66b897f9514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 0, Loss: 0.340255\n",
            "Epoch: 50, Loss: 0.057327\n",
            "Epoch: 100, Loss: 0.011549\n",
            "Epoch: 150, Loss: 0.002853\n",
            "Epoch: 200, Loss: 0.004997\n",
            "Epoch: 250, Loss: 0.002319\n",
            "Accuracy: 0.820000\n",
            "Epoch: 0, Loss: 0.372197\n",
            "Epoch: 50, Loss: 0.015475\n",
            "Epoch: 100, Loss: 0.000065\n",
            "Epoch: 150, Loss: 0.000330\n",
            "Epoch: 200, Loss: 0.000209\n",
            "Epoch: 250, Loss: 0.000188\n",
            "Accuracy: 0.808000\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "cifar10 = datasets.CIFAR10('data', train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10('data', train=False, download=True)\n",
        "\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "cifar10 = datasets.CIFAR10('data', train=True, download=False,\n",
        "                          transform=transforms.ToTensor())\n",
        "\n",
        "cifar10 = datasets.CIFAR10('data', train=True, download=False,\n",
        "                          transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                                                   (0.2470, 0.2435, 0.2616))\n",
        "                          ]))\n",
        "cifar10_val = datasets.CIFAR10('data', train=False, download=False,\n",
        "                          transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                                                   (0.2470, 0.2435, 0.2616))\n",
        "                          ]))\n",
        "\n",
        "label_map = {0: 0, 2: 1}\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n",
        "\n",
        "#1 layer\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "\n",
        "neuron_count = 512\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, neuron_count),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(neuron_count, 2),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 300\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "      print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Accuracy: %f\" % (correct / total))\n",
        "\n",
        "#3 layer\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(256, 2))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 300\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "      print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ]
    }
  ]
}