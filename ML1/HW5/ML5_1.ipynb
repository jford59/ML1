{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC11n74w7sxvbg5XF72GbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jford59/ML1/blob/main/ML1/HW5/ML5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JiciXKw7pa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4f8339-c3b5-457b-b8cb-5e04d92a5a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.995874\n",
            "Epoch 1000, Loss 2.927735\n",
            "Epoch 1500, Loss 2.927646\n",
            "Epoch 2000, Loss 2.927647\n",
            "Epoch 2500, Loss 2.927647\n",
            "Epoch 3000, Loss 2.927647\n",
            "Epoch 3500, Loss 2.927647\n",
            "Epoch 4000, Loss 2.927647\n",
            "Epoch 4500, Loss 2.927647\n",
            "Epoch 5000, Loss 2.927647\n",
            "Epoch 500, Loss 7.625459\n",
            "Epoch 1000, Loss 3.763572\n",
            "Epoch 1500, Loss 3.076389\n",
            "Epoch 2000, Loss 2.954113\n",
            "Epoch 2500, Loss 2.932355\n",
            "Epoch 3000, Loss 2.928484\n",
            "Epoch 3500, Loss 2.927795\n",
            "Epoch 4000, Loss 2.927672\n",
            "Epoch 4500, Loss 2.927651\n",
            "Epoch 5000, Loss 2.927647\n",
            "Epoch 500, Loss 25.076952\n",
            "Epoch 1000, Loss 21.567631\n",
            "Epoch 1500, Loss 18.614321\n",
            "Epoch 2000, Loss 16.128931\n",
            "Epoch 2500, Loss 14.037330\n",
            "Epoch 3000, Loss 12.277114\n",
            "Epoch 3500, Loss 10.795785\n",
            "Epoch 4000, Loss 9.549165\n",
            "Epoch 4500, Loss 8.500057\n",
            "Epoch 5000, Loss 7.617168\n",
            "Epoch 500, Loss 28.788887\n",
            "Epoch 1000, Loss 28.346630\n",
            "Epoch 1500, Loss 27.911959\n",
            "Epoch 2000, Loss 27.484722\n",
            "Epoch 2500, Loss 27.064796\n",
            "Epoch 3000, Loss 26.652039\n",
            "Epoch 3500, Loss 26.246349\n",
            "Epoch 4000, Loss 25.847593\n",
            "Epoch 4500, Loss 25.455656\n",
            "Epoch 5000, Loss 25.070423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.2815,  1.2815, -1.4047], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "\n",
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n",
        "                    3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
        "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "\n",
        "t_un = 0.1 * t_u\n",
        "\n",
        "def model(t_u, w1, w2, b):\n",
        "    return w1 * t_u + w2 * t_u + b\n",
        "\n",
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean()\n",
        "\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "params.grad is None\n",
        "\n",
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "loss.backward()\n",
        "\n",
        "params.grad\n",
        "\n",
        "if params.grad is not None:\n",
        "    params.grad.zero_()\n",
        "\n",
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        if params.grad is not None:  # <1>\n",
        "            params.grad.zero_()\n",
        "\n",
        "        t_p = model(t_u, *params)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():  # <2>\n",
        "            params -= learning_rate * params.grad\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "    return params\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-1,\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True),\n",
        "    t_u = 0.1 * t_un,\n",
        "    t_c = t_c)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True),\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-3,\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True),\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-4,\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True),\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)"
      ]
    }
  ]
}